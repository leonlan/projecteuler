#+PROPERTY: header-args :tangle yes :exports both

* Project Euler

** Solved problems

*** Problem 69: Totient maximum
Can be solved analytically. Otherwise, use a totient sieve.

*** Problem 70: Totient permutation
Use a totient sieve to solve this problem.

*** Problem 74: Digit factorial chains
This type of problem is solved using a cache, which keeps track of intermediate results. Without a cache, brute-forcing would be ridiculously expensive.

*** Problem 92: Square digit chains
This type of problem is best solved using a cache.b

*** [[https://projecteuler.net/problem=183][Problem 183: Maximum product of parts]] :optimization:
This question has bothered me for quite a long time. When I looked at this problem for the first time, I thought it would be a simple convex optimization problem which I could solve using =cvxpy= or some other convex solver. However, not realizing that I could rewrite the optimization problem, I became stuck and never managed to do this.

Then I realized that $(N/k)^k$ is an *unconstrained optimization problem* and might actually be differentiable, although it was not so obvious how to. I looked up on how to differentiate any function in the form of $x^x$ and landed upon the topic of [[http://mathcentral.uregina.ca/QQ/database/QQ.09.03/cher1.html][implicit differentiation]]. Using the techniques outlined there, I computed that $k^* = \frac{N}{e}$ is the maximizer. However, we cannot use non-integer valued solutions, so we need to round $k$. Using the code below I empirically tested that rounding to the nearest integer is always best.

#+BEGIN_SRC python :results output :session p183
from math import exp

def P(r, k):
    return r**k

def optimize(N):
    """Finds k such that P(N, k) is maximized."""
    best_k, best_P = 0, 0
    for k in range(2, N):
        r = N/k
#        print(k, r, P(r, k))
        if P(r, k) >= best_P:
            best_P = P(r, k)
            best_k = k
    return best_k, round(N*exp(-1)), best_P

def brute_force(d=15):
    """Iterate over the first 15 problems."""
    print("Best k (bruteforce), best k (using N/e), best P (bruteforce)")
    for i in range(5, d):
        print(optimize(i))

brute_force()
#+END_SRC

#+RESULTS:
#+begin_example
Best k (bruteforce), best k (using N/e), best P (bruteforce)
(2, 2, 6.25)
(2, 2, 9.0)
(3, 3, 12.703703703703706)
(3, 3, 18.96296296296296)
(3, 3, 27.0)
(4, 4, 39.0625)
(4, 4, 57.19140625)
(4, 4, 81.0)
(5, 5, 118.81376000000002)
(5, 5, 172.10367999999994)
#+end_example

So that makes finding the optimal $k$ an easy job. However, how do we decide that $M(N)$ is a terminating decimal or not? Googling brought me to the following [[https://magoosh.com/gmat/math/basics/gmat-math-terminating-and-repeating-decimals/#:~:text=expression%20will%20terminate.-,If%20the%20prime%20factorization%20of%20the%20denominator%20of%20a%20fraction,then%20the%20decimal%20expression%20repeats.][theorem]]:

#+BEGIN_SRC
If the prime factorization of the denominator of a fraction has only factors of 2 and factors of 5, the decimal expression terminates.  If there is any prime factor in the denominator other than 2 or 5, then the decimal expression repeats.
#+END_SRC

That's pretty easy to check! Also, we just need to check this fact for $N/k^*$, since putting a power on it just changes the multiplicity of existing prime factors. Below I wrote an example for the =is_terminating= function.

#+BEGIN_SRC python :results output :session p183
from sympy import factorint
from collections import defaultdict

def is_terminating(n, d):
    """Checks if the fraction n/d is terminating or not."""
    fn = defaultdict(int, factorint(n))
    fd = defaultdict(int, factorint(d))

    # Cancel terms which occur both in fn and fd
    for k, v in fn.items():
        c = min(fn[k], fd[k])
        fn[k] -= c
        fd[k] -= c

    # Check if denominator only contains 2s and 5s
    for k, v in fd.items():
        if k not in [2, 5]:
            if v > 0:
                return False
    return True

# Example from the problem statement
print(is_terminating(14641, 256))
#+END_SRC

#+RESULTS:
: True
*** [[https://projecteuler.net/problem=197][Problem 197: Investigating the behaviour of a recursively defined sequence]] :bruteforce:
Not sure what to think of this problem. I wrote the code below and did some googling, and it turns out that this sequence converges really fast, so we can just take N = 10000 and get the answer.. But I'm kind of disappointed that it's easy to compute without having to think about the math.

#+BEGIN_SRC python :results output
from math import floor, pow
import numpy as np

def f(x):
    return floor(pow(2, 30.403243784 - pow(x, 2))) * pow(10, -9)

K = 10000
u = np.zeros(K)
u[0] = -1
for i in range(1, K):
    u[i] = f(u[i-1])
print(u[i-1],u[i])

#+END_SRC

#+RESULTS:
: 1.029461839 0.681175878

From the discussion board, I read that the math is actually pretty neat.

*** [[https://projecteuler.net/problem=240][Problem 240: Top Die]] :recursion:
Sometimes, it's hard to explain a problem. In such cases, I often believe that I do not fully grasp the theory yet, which is also the case here. I won't be able to write a complete solution (unlike Problem 259 for instance) but I'll write down the initial problems and my solutions.

**** Initial struggles
- How do we deal with permutations of dice? For instance, 66333 is a permutation of 33366. But both have the property that the k-sum (e.g. sum of largest k numbers) is 15.
- A brute-force approach would be to compute the product of all dice, which comes down to 12^20 possible options. This number is too large, so how can we reduce the search space?

**** Solutions
- We only need to compute all non-increasing sequences of k numbers for which the sum is 15 (=: S).
- We can write a recursive approach to generate all such numbers.
- We use a character to integer mapping to represent 2-digit numbers as 1 character, e.g. ='a' = 12= and ='l' = 1=.
*** [[https://projecteuler.net/problem=259][Problem 259: Reachable Numbers]] :dp:
This question has been on my mind for a long, long time. It's related to [[https://projecteuler.net/problem=93][Problem 93: Arithmetic expressions]] in the way that we need to construct arithmetic expressions restricted to some set of numbers. I'm also a big fan of the game 24, which is the reason why I'm excited about this problem.

The idea of this question is quite simple: we need to find the sum of all reachable numbers. How can we construct an algorithm that computes all these reachable numbers in a reasonable amount of time? My intuition says: dynamic programming.

1-subsets
2-subsets

Define =S[n][l][r]= as the set of numbers that can be constructed using $n$ consecutive numbers, starting at index $l$ and ending at index $r$ (inclusive). For ease of computation, we let the indices start at $1$ and end at $9$. If $n$ is larger than $r-l+1$, then the set becomes empty.  Before we explain why this definition will become helpful, some examples are given:
#+BEGIN_SRC
S[1][i][i] = {i} for all i = 1, ..., 9
S[2][1][2] = {1+2, 1-2, 1*2, 1/2}
S[2][1][4] = {} # Empty set
S[3][1][3] = {(1+2) + 3, (1-2) + 3, ...,
              (1+2) - 3, (1-2) - 3, ...,
              ...
              ...
              1 * (2+3), 1 * (2-3), ...,
              1 / (2+3), 1 / (2-3), ...,
             }
#+END_SRC

Our goal is eventually to compute =S[9][1][9]=, i.e. the set of numbers that can be constructed using $n$ numbers, starting at index $1$ and ending at index $9$. Thus, the main question becomes: how can we get there? As the above example illustrates, to compute =S[3][1][3]=  we can compute the set of elements of =S[2][1][2] x S[1][3][3]= and =S[1][1][1] x S[2][2][3]=, where =x= is the placeholder for any operator =+, -, *, /=, which we will call the global operator from now on (I know, using =x= is confusing, but =*= here is multiplication).

Can we be 100% sure that we can compute =S[3][1][3]= using the two operations above? Do we also need to consider numbers that can be constructed as the operation =S[1][1][1] x S[1][2][2] x S[1][3][3]= for instance? There's fortunately no need for that: you can prove that if we use more than 1 global operator =x=, then it is a subset of a larger subset. For example, =S[1][1][1] x S[1][2][2]= is a subset of =S[2][1][2]= by construction. Hence, we can find any set =S[n][l][p]= by consider the global operation between two sets =S[m][i][j] x S[k][x][y]= such that:
- =m+k = n=
- =y-i+1 = n=: in words, it must be a consecutive string of digits
- =x = j-1=: actually redundant, but also makes sure that the consecutive string of digits is considered. We only need 2 out 3 conditions listed here.

This finishes the theoretic part of our algorithm. One more thing: we also need to include concatenated numbers. Hence, each set =S[n][l][p]= should be initialized with the possibly concatenated numbers. See below for the code that computes this.

#+BEGIN_SRC python
import numpy as np
N, L, R = 10, 10, 10

S = [[[set() for r in range(R)] for l in range(L)] for n in range(N)]

def concat_num(l, r):
    """Returns the concated number starting at l and ending at r."""
    s = ''.join([str(x) for x in range(l, r+1)])
    return int(s)

for n in range(1, N):
    for l in range(1, L):
        for r in range(1, R):
            if r-l+1 == n:
                S[n][l][r].add(concat_num(l, r))

#+END_SRC

Let's now finish the algorithm. As mentioned before, we can construct any set =S[n][l][p]= through a global operation between two other sets. It should be easy to see that all the sets with $n=1$ are just the initialized numbers. That means that we can start constructing the sets with $n=2$. We start at index $1$ and keep going until (and including) our start position at $9-n+1=8$. Once we have computed the subsets with size $n=2$, we continue with $n=3$, and then $n=4$, etc. until we reach $n=9$. Et voila, putting all this together in code yields a perfect way to find all the reachable numbers, which is stored in =S[9][1][9]=.


Two details that I have not touched upon are:
- How to create the global operator =x=, but that should not be too hard to figure out; and
- Filtering the final solution =S[9][1][9]= on positive integers. Also beware of floating point errors. This depends on the programming language that you use. If you use Python, I would recommend using the [[https://pypi.org/project/quicktions/][quicktions]] library for fractional arithmetic support.

*** [[https://projecteuler.net/problem=265][Problem 265: Binary circles]] :recursion:
Problem understanding
- Start with [0]*N.
- What are the possible binary circle representations?
- Each subsequence in 2*N must appear exactly once.

If I extend my current substring, then I can only append 0 or 1. That means that the total possible number of substrings I can make is O(2^(2^N)). Luckily, we don't need to compute them all. Here is a code that I wrote really quick:

#+BEGIN_SRC python :results output
def is_substring(s, substring):
    return substring in s

def check(s, N):
    S = set()
    s = s + s[:N-1]
    return len(set([s[i:i+N] for i in range(2**N)])) == 2**N

L = []

def extend(seq, tail, N):
    if len(seq) == 2**N:
        if check(seq, N):
            L.append(seq)
    else:
        for i in range(2):
            candidate = tail[1:] + f'{i}'
            if not is_substring(seq, candidate):
                extend(seq + f'{i}', candidate, N)

extend('000', '000', 3)
print(L)
#+end_src

#+RESULTS:
: ['00010111', '00011101']

Surprisingly, it turns out that this also works fine for $N=5$. It even terminates within 1 second. The =check= procedure might be a bit expensive, but there aren't many 32-bit candidates that we need to check, so it is not a big issue.
*** [[https://projecteuler.net/problem=287][Problem 287: Quad-tree encoding (a simple compression algorithm)]] :recursion:
Let's first get a better understanding of the problem instance by visualizing the matrix for small $N$:
#+BEGIN_SRC python :results output
import numpy as np
from itertools import product


N = 3
A = np.zeros((2**N, 2**N))

def is_black(coord, N):
    x, y = coord
    return (x-2**(N-1))**2 + (y-2**(N-1))**2 <= 2**(2*N-2)

def is_white(coord, N):
    x, y = coord
    return not is_black(x, y, N)

for i, j in product(range(2**N), repeat=2):
    if is_black((i, j), N):
        A[2**N-j-1][i] = 1

print(A)
#+END_SRC

#+RESULTS:
: [[0. 0. 1. 1. 1. 1. 1. 0.]
:  [0. 1. 1. 1. 1. 1. 1. 1.]
:  [0. 1. 1. 1. 1. 1. 1. 1.]
:  [1. 1. 1. 1. 1. 1. 1. 1.]
:  [0. 1. 1. 1. 1. 1. 1. 1.]
:  [0. 1. 1. 1. 1. 1. 1. 1.]
:  [0. 0. 1. 1. 1. 1. 1. 0.]
:  [0. 0. 0. 0. 1. 0. 0. 0.]]

This kind of looks like a circle (of ones) in the middle. This makes our life much easier, because checking if a 'split' square is of 1 color can be done in checking the corners of the square (why?). Recursion is then feasible, because we can shortcut many subproblems and don't need to consider all $2^N$ possible subproblems.

My solution implements the following functions:
- =is_black(coord, N)= :: Checks if a given coordinate is black or not.
- =new_coords(coord, position, N)= :: Computes new coordinates for each subproblem.
- =same_color(coords, N)= :: Checks if the corners coordinates of a square all have the same color. Could be either white or black.
- =encode(coords, N, K)= :: Recursive computation of the length of the minimal encoding.

Without any optimizations, my algorithm took about 15 minutes to finish. I did some fiddling and managed to find the following optimizations to get it down to 4 minutes:
1. I sped-up =same_color= by 50% by summing the coordinate-colors (0 white, 1 black) and checking if it is either 0 (all white) or 4 (all black).
2. In =is_black=, I computed =2**(2N-2)= in every function call, but this is really expensive considering that this would be done for all coordinates. Instead, pre-computing this value decreased the speed by 33%.
3. In fact, using =math.pow= is much more efficient than =**= for some reason. This also increased my algorithm by about 50%.
4. In the discussion board people also talked about a symmetry (top left is rotational symmetric to right bottom) which could also speed up the code by 25%. I did not implement this.

As mentioned on the discussion board, it should be possible to get a pure python code to run in under 1 minute but it will require more optimizations. More specifically, computing =is_black= could be optimized much further (for example, a pre-computed table for (x, y) values for which the coordinates are guaranteed to be black).

*** [[https://projecteuler.net/problem=389][Problem 389: Platonic Dice]]        :probability:dp:generating_functions:
We want to calculate the variance of a random variable $X$, which is given by $$Var(X) = \sum_{i=1}^n P(X=x_i)(x_i-\mu)^2,$$ where $x_i$ are the possible outcomes of $X$ for all $i=1, \dots, n$.

If you've taken a course in probability before, then you might have heard of the law of total probability. This theorem states that if $B$ is a finite partition of a sample space, then for each event $A$ in the same probability space we can compute $$P(A) = \sum_n P(A \mid B_n)P(B_n).$$ This can be exploited to compute the probability distributions for any of the random variables $T$, $C$, $O$, etc. and subsequently we can compute the variance of $I$.

To illustrate this, let's calculate the probability distribution of $T$. Since $T$ is a unbiased, single 4-sided die, then we know that $$P(T=1) =  P(T=2) = P(T=3) = P(T=4) = 0.25.$$ This was quite easy, so how about the next one? Here we need to apply the law of total probability since we are taking a sum that depends on a random variable. For instance, consider $C = \sum_{t=1}^T U(6)$ where $U(6) \sim Unif(1, 6)$, i.e., the sum of $T$ i.i.d. 6-sided dice. By the law of total probability, it follows that we can calculate this as $$P(C=x) = \sum_{t} P\Big(\sum_{i=1}^t U(6) = x\Big) P(T=t).$$ Here, $T$ has 4 possible events (which were considered above), so the only thing that remains is that we need to $P\Big(\sum_{i=1}^t U(6) = x\Big)$ for each $t$, which are the possible values of $T$. This is the most challenging part of the question.

My solution is through dynamic programming. It runs really slow (20 min) it does compute the right answer. The solution thread shows that we could have computed the problem using generating functions:
$$T(x) = \frac14 \sum_{k=1}^4 x^k$$
$$C(x) = T\left(\frac16 \sum_{k=1}^6 x^k\right)$$
$$\ldots$$
$$I(x) = D\left(\frac1{20} \sum_{k=1}^{20} x^k\right)$$
$$V = I''(1) + I'(1) - I'(1)^2$$
which is really cool. I don't know enough about it, but I'll be sure to refer to this once I need it again.

*** [[https://projecteuler.net/problem=650][Problem 650: Divisors of Binomial Product]] :binom:
**** Definitions
For the sake of readability, let's repeat the definitions from the problem here. Let $$B(n) = \displaystyle \prod_{k=0}^n {n \choose k}$$ be the product of binominal coefficients, let $$D(n) = \displaystyle \sum_{d|B(n)} d$$ be the sum of divisors of $B(n)$, and let $$S(n) = \displaystyle \sum_{k=1}^n D(k)$$ be the sum of all $D(k)$ up to $n$. The goal is to compute $S(20000)$, which suggests that we are allowed to find a $O(n^2)$ algorithm.

**** $D(n)$: Sum of divisors <=> prime factorization
Computing the sum of divisors is a common idea in Project Euler. Luckily, we do not need to compute all possible divisors of a number $n$ to find its sum of divisors. Instead it suffices to compute the prime factorization, more info can be found on [[https://en.wikipedia.org/wiki/Divisor_function][Wikipedia]]. Given the prime factorization of $n$, then you take each different prime factor and add together all its powers up to the one that appears in the prime factorization, and then multiply all these sums together to obtain the sum of divisors! We denote $\sigma(n)$ as the sum of divisors. This means that if we can find the prime factorization of $B(n)$, then we can easily compute $D(n)$.

**** $B(n)$: Compact expression
Finding a compact expression will be essential to compute the prime factorization. To illustrate this, let's consider an example for $B(5)$. Writing out the product in both choose and factorial form gives $$\binom{5}{0} \cdot \binom{5}{1} \cdot \binom{5}{2} \cdot \binom {5}{3} \cdot \binom {5}{4} \cdot \binom {5}{5},$$ $$ = \frac{1}{1} \cdot \frac{5}{1} \cdot \frac{5\cdot 4}{1 \cdot 2} \cdot \frac{5\cdot 4}{1 \cdot 2} \cdot \frac{5}{1} \frac{1}{1}.$$ Observe that the binomial coefficient is symmetric around $n/2$, so we essentially only need to look at the first 3 terms and then square it to yield the full expression. Doing this for the current example, we obtain $$\Big(\frac{5^2 \cdot 4^1}{1^2 \cdot 2^1}\Big)^2.$$ Clearly, there is some pattern in here, and if you try for yourself then you can see the following expression emerge (if $n$ is odd): $$\Big(\frac{n^{k}\cdot (n-1)^{(k-1)} \cdot \dots \cdot (n-k+1)^1}{1^k \cdot 2^{k-1} \cdot \dots \cdot k^1}\Big)^2 = \frac{n^{2k}\cdot (n-1)^{2(k-1)} \cdot \dots \cdot (n-k+1)^2}{1^{2k} \cdot 2^{2(k-1)} \cdot \dots \cdot k^2},$$ where $k = \lfloor \frac{n}{2} \rfloor$. There is an exception if $n$ is even, because then we should exclude the 'middle' element in the square to prevent overcounting. The expression then becomes (check this using an example, e.g. $B(10)$):
$$\Big(\frac{n^{k-1}\cdot (n-1)^{k-2} \cdot \dots \cdot (n-k+2)^1}{1^{k-1} \cdot 2^{k-2} \cdot \dots \cdot (k-2)^1}\Big)^2 \cdot \frac{n \cdot (n-1) \cdot \dots \cdot (n-k+1)}{1 \cdot 2 \cdot \dots \cdot k} = \frac{n^{2k-1}\cdot (n-1)^{2(k-1)-1} \cdot \dots \cdot (n-k+1)^1}{1^{2k-1} \cdot 2^{2(k-1)-1} \cdot \dots \cdot k^1},$$
where $k = \frac{n}{2}$ again.

**** The algorithm
Now that we have a compact expression for $B(n)$, we can compute $D(n)$ quite easily. For each $n$, we construct a prime-factors array for $B(n)$. Using a pre-computed prime factorization table, we can translate each of the factors in the numerator and denominator of $B(n)$ to a prime factor, e.g. $4^2$ becomes $2^4$, and count the powers. Once we have considered all terms we have obtained the full prime factorization of $B(n)$ and we can use the discussed method for computing $D(n)$. This procedure will take about $O(n)$, and since we need to consider $n$ numbers, the final algorithm will have complexity $O(n^2)$ as desired. My code runs in about 3 minutes, which is a bit slow. The solutions thread shows that there are much more compact ways to write $B(n)$, which will definitely speed up the algorithm.

*** [[https://projecteuler.net/problem=739][Problem 739: Summation of Summations]] :catalan_numbers:
This is the first time that I tried to solve a problem from the recent section, since I always perceived these problems as too difficult for me to solve. Then somehow I got my housemate Dorian hooked about Project Euler and asked me to show him the newest problem at the time, which happened to be Problem 739. Not expecting the tiniest little bit, I showed Dorian the problem description on my iPad and I continued to solve Problem 389, which I was solving myself that evening.

What happened next surprised me quite a bit. Dorian worked out the pattern for up to $n=8$ and found on Google that this corresponded to the *Catalan numbers*. In particular, calculating $f(n)$ could be calculated by finding the coefficients corresponding to $n$-th row of the *Catalan triangle*. Given that we are calculating an order $m=2$ Catalan triangle, the $n$-th row and $k$-th element can be calculated as follows:
\[C_{m}(n,k)={\begin{cases}\left({\begin{array}{c}n+k\\k\end{array}}\right)&\,\,\,0\leq k<m\\\\\left({\begin{array}{c}n+k\\k\end{array}}\right)-\left({\begin{array}{c}n+k\\k-m\end{array}}\right)&\,\,\,m\leq k\leq n+m-1\\\\0&\,\,\,k>n+m-1\end{cases}}\]

Knowing that we had to compute $n=10^8$ with $k \leq n$, we needed to find an efficient way to compute $C_2(n, k)$ in constant time, since an $O(n)$ algorithm is needed to compute this problem in reasonable amount of time. Since Dorian already made some huge success in figuring out the pattern for calculating this solution, I couldn't just let the problem hanging here. So I googled how to calculate large binominal coefficients modulo a prime number $p$, and stumbled upon this very well-written guide on exactly this topic: [[https://fishi.devtail.io/weblog/2015/06/25/computing-large-binomial-coefficients-modulo-prime-non-prime/][Computing large binomial coefficients modulo prime]]. The key idea is to use Fermat's Little Theorem to compute each binomial coefficient by finding the multiplicative inverse of the denominator.

Using these observations, the algorithm is actually very simple. Define $C(n, k) = C^+(n, k) - C^-(n,k)$ for $k \geq 2$. Then we can compute the next element through the following recurrence relation: $$C^+(n, k+1) = C^+(n, k) \frac{n+k}{k}, \quad C^-(n,k +1)\frac{n+k}{k-2}$$ and hence $$C(n, k+1) = C^+(n,k+1)-C^-(n,k+1).$$ Essentially, this is what my algorithm does with some additional modulo computations (and modulo inverse for the denominator).

Although my algorithm doesn't run so fast (about 15 minutes), it does compute the right answer! I'm happy about the result since I did not expect to solve it anyhow in the first place. Thanks to Dorian for his perseverance.


** Work in progress
*** TODO [[https://projecteuler.net/problem=209][Problem 209: Circular Logic]]
**** Definitions
What are 6-input binary truth tables?

#+BEGIN_SRC python :results output
abcdef = 2**6
print(f"There are {abcdef} distinct 6-bit inputs.")
print(f"There are {2**abcdef} possible 6-input binary truth tables t.")
#+END_SRC

#+RESULTS:
: There are 64 distinct 6-bit inputs.
: There are 18446744073709551616 possible 6-input binary truth tables t.

Consider the given formula: =τ(a, b, c, d, e, f) AND τ(b, c, d, e, f, a XOR (b AND c)) = 0=. We define =t1= and the first part, and =t2= as the second part. Then, instead of evaluating this expression, we consider the possible such that =t1 AND t2 = 1=, since this case is much easier to consider: we need to find all =t= such that for every =abcdef= both =t1= and =t2= are true. But here is what I get stuck at: there exists only one function =tau= such that =t1= is always true regardless of the input. That would simply be the function =tau= that always returns true.

*** TODO [[https://projecteuler.net/problem=277][Problem 277: A Modified Collatz sequence]]
The best way to explain this question is by demonstrating some examples. The key idea is that it is all about periodicity.

For example, let's take the sequence 'DDD'. Which numbers can start with such a subsequence? Knowing that D can only occur if the current number is divisible by three with no remainder, it follows that only numbers that are three-times divisible by 3 with no remainder can start with subsequence 'DDD'.

81 is an example of such number. If we let $a_{1}=81$, then we get $a_{2} = 9$, $a_{3} = 3$ and $a_{4}=1$. As you can see, all numbers $a_{1}, a_{2}$ and $a_{3}$ are divisible by 3.

The previous example was a very easy case, so let's up the difficulty a bit by considering the subsequence 'UDD'. In this case, the step U occurs if our initial number has remainder 1, so contenders for $a_{1}$ are $1, 4, 7, 10, ...$. However, which of these numbers are also contenders for $a_{2}$, knowing that the transformation $U(a_1)$ must give a number that is divisible 3 (since the next step is D)?

Here comes the key observation: For each of the candidate numbers of $a_1$, the transformed numbers $a_2 = U(a_1)$ are periodic. Let's show this:
#+BEGIN_SRC python :results output
def U(a):
    return (4*a+2)//3

contenders = [1, 4, 7, 10, 13]
transformed = [U(a) for a in contenders]
periodicity = [a % 3 for a in transformed]

print(contenders)
print(transformed)
print(periodicity)
#+END_SRC

#+RESULTS:
: [1, 4, 7, 10, 13]
: [2, 6, 10, 14, 18]
: [2, 0, 1, 2, 0]

Looking at the periodicity of the transformed contender numbers, we see that the /valid/ contenders for $a_1$ are 4 and 13, because $U(4)$ and $U(13)$ have remainder 0 which is needed for the next step D.

We can now start to think about the first steps our algorithm. Since we are dealing with periodicity, we only need to make sure that our contender numbers (in some iteration) follow the periodicity that is needed for the upcoming steps. It would be quite problematic to keep the entire array =[1, 4, 7, 10, ...]= (up to the lower bound, 10^15 in this case) in memory, but we really don't need to do that. It is sufficient to keep just the smallest number which is a valid contender at each iteration.

Applying this logic it to our current example: consider the first iteration. The first valid contender for the step U is the number 1. We store this in a variable =start= and go on to the next iteration. For the next step D, we check the remainder of $U(1)$ and see that it is 2. That's not good, since we need remainder 0. But what we do know (from the periodicity of the remainders) is that the next contender (4) of the 1st iteration will get remainder 0 if it is transformed by U ($U(4) = 6$). So we can change our =start= variable to 4. Note that 13 would also be a contender for sequence UD, but we do not need to consider that because it is not the smallest valid contender. In fact, we only needed to consider at most 2 contenders to find the first new valid contender. That is, we only needed to consider 1, 4, and 7 to find the first valid contender that satisfies the sequence UD. For example, since $U(10)$ and $U(1)$ have the same remainder, it would be unnecessary to check $U(10)$ again.

The jumps between the start number and valid contenders become larger and larger in each iteration. In the first iteration we need to consider 0, 1, 2, which has intermediate jumps of 1. In the second iteration, we need to consider 1, 4, 7, which has intermediate jumps of 3. In the third iteration, you can show that we need to consider 4, 13 and 22, which have intermediate jumps 9. And if we would go on the next iteration, then we would see that the intermediate jumps become 27. The formula for the jumps is 3^(i-1), where i is the i-th iteration.

There are many more subtleties to be explained, but I'll keep it to this for now.
#+BEGIN_SRC python
start = 0
for each iteration i:
    compute the period of start
    compute the needed period for the next step
    compute the needed jumps j to get the right period
    start += j * jump


keep adding jump to start until we reach a > bound.
#+END_SRC


#+BEGIN_SRC python :results output
step2period = {'D': 0, 'U': 1, 'd': 2}

Dp = [0, 1, 2]
Up = [0, 1, 2]
dp = [2, 1, 0]

start = 0
for i, step in enumerate(sequence):
    # Initialization
    if i == 0:
        start = step2period[step]
    else:
        jump = 3**i
        # if start is not at the right period,
        # jump start to another position
        current = compute_period(start, subseq)
        target = step2period[step]
        j = compute_jumps(current, target, step)
        start += j * jump

jump = 3**(i+1)
while start < lb:
    start += jump

print(start)

#+END_SRC

*** TODO [[https://projecteuler.net/problem=375][Problem 375: Minimum of subsequences]]
#+BEGIN_SRC python
import numpy as np

N = 2*10**8
S = np.zeros(N)
S[0] = 0
for i in range(1, N):
    S[i] = S[i-1] ** 2 % 50515093


def p375_bf(N):
    """Bruteforce algorithm for p375."""
    ...
#+END_SRC


*** [[https://projecteuler.net/problem=300][Problem 300: Protein folding]]
Problem:
- Suppose you have a random H-P string of size 2**N
- What is the expected number of H-H contact points?

Thoughts
- 0 H => 0 points
- 1 H => 0 points
- 2 H => 1 point or 0 point
  For example, HPH can never have a point connected.
  But HHP can always get a point connected

Steps:
- Suppose
- Find the optimal string(s)
- Compute all possibilities of H/P element placements
- Calculate the H-H contact points, sum them up

**** TODO How many optimal foldings exist?

**** TODO

*** [[https://projecteuler.net/problem=166][Problem 165: Intersections]]
Sketch:
- Given (x1, y1) and (x2, y2), compute f(x) = ax + bx
- True intersection point if any endpoint is not a solution to f(x)

*** [[https://projecteuler.net/problem=166][Problem 166: Criss Cross]]
From left to right, top to bottom, define the variables $x_{i}$ for $i=1, \dots, 16$ as the value at position $i$. We can then setup a system of linear equations:
\begin{align*}
x_{1}+x_{2}+x_{3}+x_{4} = d \\
x_{5}+x_{6}+x_{7}+x_{8} = d \\
x_{9}+x_{10}+x_{11}+x_{12} = d \\
x_{13}+x_{14}+x_{15}+x_{16} = d \\
x_{1}+x_{5}+x_{9}+x_{13}=d \\
x_{2}+x_{6}+x_{10}+x_{14}=d \\
x_{3}+x_{7}+x_{11}+x_{15}=d \\
x_{4}+x_{8}+x_{12}+x_{16}=d \\
x_{1}+x_{6}+x_{11}+x_{16}=d \\
x_{4}+x_{7}+x_{10}+x_{13}=d \\
\end{align*}

Ten equations with 16 variables; 6 of those variables will be free. Simplifying all those equations will yield:

....

*** [[https://projecteuler.net/problem=190][Problem 190: Maximising a weighted product]]
Problem description
- For fixed m, maximize product(xi^i) s.t. sum(xi) = m.

I think this might be a geometric program.. The objective function is a monomial whereas the constraint is a polynomial.

#+BEGIN_SRC python :results output
from cvxopt import matrix, exp, log, solvers
from math import prod

m = 10

F = []
for i in range(1, m+1):
    L = [-i] + [0.]*m
    L[i] = 1
    F.append(L)
F = matrix(F)

g = log(matrix([1] + [1/m]*m))
K = [1, m]
x = exp(solvers.gp(K, F, g)['x'])
print(x)
print(int(prod([n**(i+1) for i, n in enumerate(x)])))


def solve(m):
    """Solve the geometric program for size m."""
    F = []
    for i in range(1, m+1):
        L = [-i] + [0.]*m
        L[i] = 1
        F.append(L)
        F = matrix(F)
        g = log(matrix([1] + [1/m]*m))
        K = [1, m]
        x = exp(solvers.gp(K, F, g)['x'])
    return int(prod([n**(i+1) for i, n in enumerate(x)]))

#+END_SRC

#+RESULTS:
#+begin_example
     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  4.4409e-16  2e+00  1e+00  1e+00
 1: -6.8339e+01 -6.6165e+01  1e+00  1e+00  1e+00
 2: -6.4075e+01 -5.3137e+01  9e-01  1e+00  8e-01
 3: -5.0731e+01  9.4167e+02  2e+00  1e+01  3e+00
 4: -5.2885e+09  7.1675e+09  2e-02  2e+08  3e+00
 5: -6.6921e+01 -5.4998e+01  9e-01  1e+00  8e-01
 6: -4.5237e+01 -1.5257e+01  9e-01  7e-01  6e-01
 7: -3.7263e+01 -1.1361e+01  2e-01  4e-01  3e-01
 8: -1.2080e+01 -8.2361e+00  2e-02  5e-02  4e-02
 9: -8.4987e+00 -8.3175e+00  4e-04  2e-03  5e-03
10: -8.3274e+00 -8.3217e+00  4e-06  7e-05  3e-04
11: -8.3218e+00 -8.3217e+00  4e-08  9e-07  3e-06
12: -8.3217e+00 -8.3217e+00  4e-10  9e-09  3e-08
Optimal solution found.
[ 1.82e-01]


















[ 3.64e-01]
[ 5.45e-01]
[ 7.27e-01]
[ 9.09e-01]
[ 1.09e+00]
[ 1.27e+00]
[ 1.45e+00]
[ 1.64e+00]
[ 1.82e+00]

4112
#+end_example

There is a problem for the geometric program when using $N=7$ and $N=9$. For the first one I get a numerical overflow error and for the second one the program doesn't terminate. In all other cases is works perfectly.

I tried to resolve this by creating $A$ and $b$ matrices, but I didn't get it to work properly due to rank errors. It works for $m=2$ surprisingly, but not for larger values. See below.
#+BEGIN_SRC python :results output :session p190
from cvxopt import matrix, exp, log, solvers
from math import prod

m = 4
F = []
for i in range(1, m+1):
    L = [-1.0]
    F.append(L)

# F.append(L)
print(F)
F = matrix(F)
g = log(matrix([1]))
K = [1]
A = []
for i in range(m):
    L = [1/m]*m
    A.append(L)
A = matrix(A)
b = matrix([[float(m)]*m])
print(A ,b)
x = exp(solvers.gp(K, F, g, A=A, b=b)['x'])
#+END_SRC

#+RESULTS:
#+begin_example
[[-1.0], [-1.0], [-1.0], [-1.0]]
[ 2.50e-01  2.50e-01  2.50e-01  2.50e-01]
[ 2.50e-01  2.50e-01  2.50e-01  2.50e-01]
[ 2.50e-01  2.50e-01  2.50e-01  2.50e-01]
[ 2.50e-01  2.50e-01  2.50e-01  2.50e-01]
 [ 4.00e+00]
[ 4.00e+00]
[ 4.00e+00]
[ 4.00e+00]

     pcost       dcost       gap    pres   dres
 0:  0.0000e+00  0.0000e+00  1e+00  1e+00  1e+00
#+end_example


*** [[https://projecteuler.net/problem=285][Problem 285: Pythagorean odds]]
#+BEGIN_SRC python :results output
from random import random
from math import sqrt

def draw(k):
    a = random()
    b = random()
    if round(sqrt((k*a+1)**2 + (k*b+1)**2)) == k:
        return k
    else:
        return 0

def play(K):
    score = 0
    for k in range(1, K+1):
        score += draw(k)
    return score

def simulation(k, iterations=100000):
    total = 0
    for i in range(iterations):
        total += play(k)
    return total/iterations

print(simulation(10))

#+END_SRC

#+RESULTS:
: 10.21561

*** [[https://projecteuler.net/problem=302][Problem 302: Strong Achilles Numbers]]
A positive integer $n$ is *powerful* if $p^2$ is a divisor of $n$ for every prime factor $p$ in $n$.
- We only need to consider the numbers with prime factorizations such that each prime has at least multiple 2

A positive integer $n$ is a *perfect power* if $n$ can be expressed of another positive integer.
- We do not need to consider the numbers whose prime factorizations include purely even multiples. For example, $324=2^2*3^4=2^2*(3^2)^2=18^2$. If the multiples are all even, then we can always make a single square.

A positive integer $n$ is an *Achilles number* if $n$ is powerful but not a perfect power.

A positive integer $n$ is a *Strong Achilles number* if both $S$ and $\phi(S)$ are Achilles numbers, where $\phi(S)$ is the totient function of $S$.
- The totient function can be calculated using the prime factorization

How can we efficiently go through all prime factorizations from 2**2 all the way up to 2**3 * (10**18)**(1/2)?
- Can we determine a strategy that efficiently 'predicts' when $\phi(n)$ is not an Achilles number?

#+BEGIN_SRC python :results output
from sympy import factorint
from math import prod
from collections import Counter

print(factorint(1800))
#[2:3, 3:2, 5:2]
#[2:2, 3:1, 5:1] + factors[(5-1)*(3-1)=8]

def fc(n):
    """Returns factorint counter."""
    return Counter(factorint(n))

def totient_factors(factors):
    """Calculates the totient factors given factors."""
    new_factors = Counter({k: v-1 for k, v in factors.items()})
    extra_factors = Counter(factorint(prod([k-1 for k in factors.keys()])))
    return new_factors + extra_factors

print(totient_factors(Counter(factorint(1800))))
#+END_SRC

#+RESULTS:
: {2: 3, 3: 2, 5: 2}
: Counter({2: 5, 3: 1, 5: 1})


*** [[https://projecteuler.net/problem=333][Problem 333: Special partitions]] :bruteforce:
My most important observations are:
- There are not so many numbers below $N$ that can be expressed *only* as $2^i*3^j$. So we might want to pre-compute all these numbers. We call such numbers *partition numbers*.
- Given two partition numbers $x$ and $y$, when do they divide each other? By the unique prime factorization theorem, we know $x | y$ if both exponents of $x$ are less or equal element-wise than the exponents of $y$. To give an example: $1=2^0x3^0$ divides $16=2^4x3^0$ because $0 \leq 4$ and $0 \leq 0$. We call $x$ and $y$ *neighbors* if $x$ divides $y$ or $y$ divides $x$.

With this, we can simply create a tree for each $p$ to brute-force all possible legible sets of partition numbers.

<2020-11-11 Wed> The case for n = 100 is solved, but it takes way too long to solve n = 10^6. In my current estimates, it would take about 17 hours. Not sure why it would take so long..
- How can we skip some prime numbers?


#+BEGIN_SRC python :results output
from collections import defaultdict
from sympy import sieve
threshold = 1000000

# This should give me all legitimate partitioning numbers
L = []
for i in range(30):
    for j in range(20):
        x = 2**i*3**j
        if x <= threshold:
            L.append([x, i, j])

L = sorted(L[1:])

# Which numbers can be put together?
# Def: neighbors
neighbors = defaultdict(list)
for (n, i, j) in L:
    for (m, x, y) in L:
        if i <= x and j <= y or x <= i and y <= j:
            pass
        else:
            neighbors[n].append(m)

# For certain p, recursively check if I can make it.
def intersection(L1, L2):
    return [x for x in L1 if x in L2]


def P(q):
    total = 0
    def partition(p, last, candidates):
        if p == 0:
            nonlocal total
            total += 1
        elif candidates:
            for n in candidates:
                if last >= n and p >= n:
                    new_candidates = intersection(candidates, neighbors[n])
                    partition(p-n, n, new_candidates)
        else:
            pass
    for (x, i, j) in L:
        if x <= q:
            partition(q-x, x, neighbors[x])
    return total
print(sum([q for q in sieve.primerange(2, 100) if P(q) == 1]))


#+END_SRC

#+RESULTS:
: 233

***

*** [[https://projecteuler.net/problem=336][Problem 336: Maximix Arrangements]]
Given configurations of 11 carriages:
- Find the maximix arrangements (the worst possible arrangement if we sort ABC... in order)
- Compute the 2011th lexicographic arrangement

How can we sort the train most efficiently according to Simon's strategy? Given a string $s$ and some letter $l$ that we need to sort, there are only two options for sorting. Either $l$ is at the end of the string, then we immediately know that 1 reverse operation will yield the desired position. If $l$ is not at the end of the string, then we can cut the string in front of $l$, reverse the right substring, and then reverse the entire string. This needs 2 operations.

For example, consider 'beacd'. We would like to sort 'a' to the right position. Since a is not at the last index, we will split the string in two by splitting in front of the letter a: 'be' and 'acd'. Next, we reverse 'acd' to 'dca' and glue the substrings back to get 'bedca'. Finally, we reverse that string to obtain 'acdeb'. We can continue this for the remainder unsorted substring 'cdeb' to calculate the number of moves needed.

See code below for the sorting mechanism.
#+BEGIN_SRC python :results output :session p333
from itertools import permutations

N = 6

char2idx = {}
for c in range(0, N):
    char2idx[chr(ord('A')+c)] = c


idx2char = {}
for c in range(0, N):
    idx2char[c] = chr(ord('A')+c)


def reverse(s):
    return s[::-1]


def partial_sort(s, t):
    """Sort the string s.t. letter t will be in front."""
    if s[-1] == t:
        return 1, reverse(s)
    else:
        i = s.index(t)
        new_string = reverse(s[:i] + reverse(s[i:]))
        return 2, new_string
    return s


def sort(s, N):
    """Returns the number of moves needed to sorts train arrangement
    according to Simon's efficient ordering strategy."""
    count = 0
    for t in range(N):
        if s:
            if s[0] == idx2char[t]:
                s = s[1:]
            else:
                num_of_moves, new_s = partial_sort(s, idx2char[t])
                count += num_of_moves
                s = new_s[1:]
        else:
            break

    return count

def brute_force(K, target):
    """Brute-force all permutations of K strings and check maximix."""
    d = {}
    arrangements = permutations(char2idx.keys())
    for s in arrangements:
        d[s] = sort(s, K)

    maximix = sorted([k for k, v in d.items() if v == max(d.values())])
    # print(max(d.values()))
    import pprint
    # print(f'These are all arrangements for N = {N}: ')
    pprint.pprint(maximix)
    print(len(maximix))
    return maximix[target-1]

# print(sort('DFAECB', N))
print(brute_force(N, 0))


#N=4 / 5
#N=5 / 7
#N=6 / 9
#N=7 / 11
#N=8 / 13


#+END_SRC

#+RESULTS:
#+begin_example
[('C', 'A', 'D', 'E', 'B', 'F'),
 ('C', 'A', 'E', 'B', 'F', 'D'),
 ('C', 'D', 'A', 'E', 'B', 'F'),
 ('C', 'D', 'F', 'A', 'E', 'B'),
 ('C', 'D', 'F', 'B', 'A', 'E'),
 ('C', 'F', 'A', 'D', 'E', 'B'),
 ('C', 'F', 'B', 'A', 'D', 'E'),
 ('C', 'F', 'B', 'E', 'A', 'D'),
 ('D', 'A', 'E', 'C', 'B', 'F'),
 ('D', 'F', 'A', 'E', 'C', 'B'),
 ('D', 'F', 'B', 'A', 'E', 'C'),
 ('D', 'F', 'B', 'C', 'A', 'E'),
 ('E', 'A', 'D', 'B', 'F', 'C'),
 ('E', 'C', 'A', 'D', 'B', 'F'),
 ('E', 'C', 'F', 'A', 'D', 'B'),
 ('E', 'C', 'F', 'B', 'A', 'D'),
 ('F', 'A', 'D', 'E', 'C', 'B'),
 ('F', 'A', 'E', 'C', 'D', 'B'),
 ('F', 'B', 'A', 'D', 'E', 'C'),
 ('F', 'B', 'A', 'E', 'C', 'D'),
 ('F', 'B', 'C', 'A', 'D', 'E'),
 ('F', 'B', 'C', 'E', 'A', 'D'),
 ('F', 'B', 'D', 'A', 'E', 'C'),
 ('F', 'B', 'D', 'C', 'A', 'E')]
24
('F', 'B', 'D', 'C', 'A', 'E')
#+end_example

The only thing that remains is finding out how many configurations we need to consider. In total, there are $11!$ possible permutations of carriages, which is about $O(n^8)$ so we need to exclude some instances. Using the =brute_force= algorithm I computed the maximix value for each $N=4, \dots, 8$ which turns out to be =[5, 7, 9, 11, 13]=, so 2 steps for each increase in $N$. That means that for 11 trains, we will need 19 moves. If we consider the =partial_sort= algorithm, this would mean that in 9 cases we have a 'double' rotation and in 1 case we only need a single rotation. Since =sort= takes about ~60 microseconds, we can make at most ~1 million functions calls to remain in the 60 second solution threshold.

**** TODO How can we construct such bad arrangements? From the results above we can observe the following:
- 'A' is never followed by 'B' in a bad arrangement. Otherwise, this will give 'B' for free by the rotation step of 'A'.
- Doesn't start with 'A' or 'B'
- Never ends with 'A'

- 'F
- *How can I get good rotations*?
#+BEGIN_SRC
N = 4
[('D', 'A', 'C', 'B'),
 ('D', 'B', 'A', 'C')]

N = 5
: [('C', 'A', 'E', 'B', 'D'),
:  ('C', 'D', 'A', 'E', 'B'),
:  ('C', 'D', 'B', 'A', 'E'),
:  ('D', 'A', 'E', 'C', 'B'),
:  ('D', 'B', 'A', 'E', 'C'),
:  ('D', 'B', 'C', 'A', 'E')]

N = 6
[('C', 'A', 'D', 'E', 'B', 'F'),
 ('C', 'A', 'E', 'B', 'F', 'D'),
 ('C', 'D', 'A', 'E', 'B', 'F'),
 ('C', 'D', 'F', 'A', 'E', 'B'),
 ('C', 'D', 'F', 'B', 'A', 'E'),
 ('C', 'F', 'A', 'D', 'E', 'B'),
 ('C', 'F', 'B', 'A', 'D', 'E'),
 ('C', 'F', 'B', 'E', 'A', 'D'),
 ('D', 'A', 'E', 'C', 'B', 'F'),
 ('D', 'F', 'A', 'E', 'C', 'B'),
 ('D', 'F', 'B', 'A', 'E', 'C'),
 ('D', 'F', 'B', 'C', 'A', 'E'),
 ('E', 'A', 'D', 'B', 'F', 'C'),
 ('E', 'C', 'A', 'D', 'B', 'F'),
 ('E', 'C', 'F', 'A', 'D', 'B'),
 ('E', 'C', 'F', 'B', 'A', 'D'),
 ('F', 'A', 'D', 'E', 'C', 'B'),
 ('F', 'A', 'E', 'C', 'D', 'B'),
 ('F', 'B', 'A', 'D', 'E', 'C'),
 ('F', 'B', 'A', 'E', 'C', 'D'),
 ('F', 'B', 'C', 'A', 'D', 'E'),
 ('F', 'B', 'C', 'E', 'A', 'D'),
 ('F', 'B', 'D', 'A', 'E', 'C'),
 ('F', 'B', 'D', 'C', 'A', 'E')]
#+END_SRC

#+BEGIN_SRC python :results output :session p333


#+END_SRC

#+RESULTS:
: 6
: ('D', 'A', 'E', 'C', 'B')


** Techniques
*** Sieving
*** Dynamic programming
*** Discrete-time Markov Chains
Discrete-time Markov Chains can be easily solved using dynamic programming. The difficult part is to define a state representation whose transition probabilities can be defined relatively efficiently.

**** DONE Problem 151: Paper sheets of standard sizes: an expected-value problem
***** State representation
X(t) = State in binary representation at time t
P(X(0) = [1, 0, 0, 0, 0]) = 1
P(X(1) = [0, 1, 1, 1, 1]) = 1
P(X(2) = [0, 0, 2, 2, 2]) = 1/4
P(X(2) = [0, 1, 0, 2, 2]) = 1/4
P(X(2) = [0, 1, 1, 0, 1]) = 1/4
P(X(2) = [0, 1, 1, 1, 0]) = 1/4

P(X(t+1) = x | X(t) = y) = q

And so on.

***** State transitions
P(X(t+1) = x | X(t) = y) = q

Given a state, what are the next possible states? What are the probabilities? The next states can be computed by taking an sheet and cutting it in half until we have obtained an A5 sheet. The probability is equal to the total number of the chosen sheet divided the total number of sheets.

***** Example
Try an example of papers with sizes A3, A4 and A5.

***** Solution
Use the state representation. Calculate P(X(t) = x) for all possible x and t = 1, 2, ..., 16.

At t = 8, 12 and 14 we can expect to find a state with only 1 sheet (respectively a single A2, A3 or A4).

**** TODO Problem 213: Flea Circus
**** DONE Problem 227: The Chase
***** State representation
X(t) = The difference between player $i$ and $j$ at time $t$
***** Transition probabilities
Players i and j can perform 4 different move combinations:
- Both players stand still, so the difference remains the same
- Both players move into the same direction, so the difference remains the same
- Both players move into opposite directions, so the difference will be +- 2
- One player will move while the other will remain still, so the difference will be +- 1

For x = 2, ..., n-2:

P(X(t+1) = x) = P(X(t) = x-2) * 1/36 + P(X(t) = x-1) * 8/16 + P(X(t) = x) * 18/16 + P(X(t) = x+1) * 8/16 + P(X(t) = x+2) * 1/36

However, for x = 0, 1, n-1, n, we have to take into account the fact that we are working on a 'circle'. That is, from state 49 and moving into the same opposite will yield 49 + 2 = 51; but a difference of 51 is never possible in a game of 100 players. Instead, the difference will "rotate" around 50, so it will become 49 -> 50 -> 49.
***** Example
Try an example with 4 players and thus N = 2.

**** DONE Problem 280: Ant and seeds
***** State representation
For each state, we need to consider the following:
- The current position (i, j)
- The state of the lower row e.g. (1, 1, 1, 1, 1) if all seeds are still there
- The state of the upper row e.g. (0, 0, 0, 0, 0) if none of the seeds have been moved
- Whether or not the ant is currently carrying a seed or not

This state can be modeled as a 5-tuple (i, j, lower, upper, carrying). The number of possibilities of states is 5*5*32*32*2 = 51200; which can be easily computed.

***** Transition probabilities
The number of transitions for each state is limited; it is namely bounded by the moving option for each ant. An ant can only move up, down, left or right, and only if those moves are legible. So for each state, there are at most 4 different states to transition to. Calculating those transitions and its probabilities is easy (see Problem 213).

The more tricky part is how to take the lower, upper and carrying variables. We shall see that it only requires two conditions:
1. If the ant is currently carrying a seed, then it will only drop its seed if it moves to a new tile in the upper row that does not contain a seed.
2. If the ant is currently not carrying a seed, then it will only pick up a seed if it moves to a new tile in the lower row that does contain a seed.

If none of the conditions hold, then lower, upper and carrying all do not change.

***** Example
I won't include an example here because the instance size is fairly small.



**** [#A] Problem 285: Pythagorean odds

**** TODO Problem 323: Bitwise-OR operations on random integers

**** TODO Problem 329: Prime Frog
**** TODO Problem 493: Under The Rainbow
** Type of problems

#+BEGIN_SRC python :result output
def h():
    N = set()
    def f(x):
        if x == 0:
            N.add(1)
        elif x > 0:
            f(x-1)
    f(10)
    return N

print(h())
#+END_SRC

#+RESULTS:
: None
